 #!/usr/bin/env ruby

# the above was generated by doom emacs!.. noice!!


# https://shopify.engineering/shopify-monolith
#  - not related to how data is stored
#  - shopify noting breaking down their monolith's processes into components, naturally, not forcefully
#    - later adopted to use rails engines, though reluctant to seperate into seperate services as it would make the whole thing more complex, taking care of a set of distributed services as opposed to a single monolith


# mostly an inquiry on how data is stored in ruby


# https://jpcamara.com/2024/12/01/speeding-up-ruby.html
#  - a good read

#  Why does it matter that Range#each is written in C? It means YJIT can’t inspect it - optimizations stop at the function call and resume when the function call returns. C functions are fast, but YJIT can take things further by creating specializations for hot paths of code. There is a great article from Aaron Patterson called Ruby Outperforms C where you can learn more about some of those specialized optimizations.

# https://railsatscale.com/2023-08-29-ruby-outperforms-c/
#   - In other words, we have a tight loop that makes many Ruby to C to Ruby calls. YJIT (as well as other JIT compilers) have a hard time optimizing these types of calls.

# First, when a JIT is optimizing a function, it tries to “cheat” to get ahead. Fundamentally, the JIT compiler is converting our Ruby code to native machine code. However, the native function that we’re trying to call is completely opaque to the JIT compiler. It cannot know what the native function will do, so it must take a conservative approach and “act like the bytecode interpreter” by reproducing exactly what the interpreter would have done. In other words, calling a C function won’t let us cheat.
#
#The second problem has to do with types the JIT detects at runtime. When the JIT compiler is compiling a function, it has the opportunity to look at the type of the parameters being passed to a function and optimize any subsequent code in that function that uses those parameters. Native functions cannot take advantage of the type information that the JIT compiler was able to collect and that means they are missing out on any optimization opportunities that could be presented with this knowledge.
#
# As an implementation detail of Ruby itself, the place where instance variables are stored is different depending on the type of the object. For example, Ruby stores instance variables on an Array in a different location than it does an Object. However, neither the Ruby code nor the C code know the type of object they will read from when each method is compiled to bytecode or machine code. But a JIT compiler is able to examine the type at runtime and generate machine code “on the fly” (or “Just In Time”) that is customized for that particular type.
#
# NOTE: gotta re-read the last few paragraphs and copy one
#  - iirc, it tries to cache machine code of commonly used things (the memory pointer of data or a function call)
#  - NOTE: now compare this with C, where you have complete control of what is stored in memory, able to store it coniguously, and clearly see via the high-level source code what's happening (cache misses, etc.).
#    - TODO: re-watch mike acton's video


# see /include/ruby/inlaternal/core/ in the ruby (MRI/CRuby) repo for impl
# ...quite complex for C.. full of macros, all over the place
# better to download the repo 'n explore it with an IDE

# basically, everything is a pointer to an object, but if the object can fit into the memory allocation of the pointer (<=63bit), then it'll store the actual data
#   - TODO: still a waste of memory for bits, null-bytes, short int, bytes, etc.


# i found this in the mruby repo
# https://github.com/mruby/mruby/blob/master/doc/internal/boxing.md
#   - although it's mruby, it sounds the same as ruby, and it even shows the bit structures
#   - THE BEST DESCRIPTION OF HOW DATA IS STORED
#     - honestly, should just hang in the dragonruby discord. Google and ai suck. Reddit is.. opinionated.

# rubykaigi2018: faster apps no memory thrash powerpoint

# can use GC.start anytime!
# GC.stat shows gc data
# GC.Profiler.enable

# tips:
# waste less
# use env vars to set initial allocation size 'n limits
#  - only rids the warmup time, not actual speed of the program
#  - use env_mem gem to figure it out for you automatically
# use jemalloc on linux?
# use the latest ruby version!



# stackoverflow.com/questions/79101837/ruby-differences-in-object-identity-of-integer

# as of v2.4

# 1. An 8-byte node that directly encodes TINY or IMMEDIATE objects directly inside it, OR is a pointer to...
# Float, bool, short symbols, <=62-bit ints, pointer, undef, nil
# NOTE: 8-bytes, 64-bit is the smallest value in ruby??

# 2. A 40-byte RVALUE structure, otherwise known as a slot, which can fully contain a SMALL object as an IMMEDIATE value OR is the starting 40 bytes (data and pointer) of…
# small objects (including small arrays, hashes, strings, etc.)
# NOTE: 408 slots per page, so ok to use a lot!

# 3. Something bigger, which uses the RVALUE data for initial part of the object and a pointer to heap memory block from malloc appropriate for the size for the object.
# large objects (including big arrays, hashes, strings)
# NOTE: careful with these for memory



# https://engineering.appfolio.com/appfolio-engineering/2019/6/25/how-ruby-encodes-references-ruby-tiny-objects-explained

# make sense? any ruby value gets a reference, even the smallest ones. Tiny values are encoded directly into the 8-byte reference. Small or large objects (but not tiny) also get a 40-byte RVALUE. Small objects are encoded directly into the 40-bytes RVALUE. And large objects don’t fit in just a reference or just an RVALUE, so they get an extra allocation of whatever size they actually need (plus the RVALUE and the reference.) For the C folks in the audience, that “extra allocation” is the same thing as a call to malloc(), the usual C memory allocation function.

# The RVALUE is often called a “Slot” when you’re talking about Ruby memory. Technically Ruby uses the word “slot” for the allocation and “RVALUE” for the data type of the structure that goes in a slot, but you’ll see both words used both ways - treat them as the same thing.



# C really treats all data as a chunk of bits with a length. There are all sorts of operations that act on chunks of bits, of course
#  - NOTE: this is what i was looking for, bit-level functions!

# What’s a pointer? Pointers are how C tracks memory. If you imagine numbering all the bytes of memory starting at zero, and the next byte is one, the next byte two and so on, you get exactly how old processors addressed memory. Some very simple embedded processors still do it that way. That’s exactly what a C pointer is - an index for a location in memory, if you were to treat all of memory as one giant vector of bytes. Memory addressing is more complicated in newer processors, OSes and languages, but they still present your program with that same old abstraction. In C, you use it very directly.
#  - NOTE: the underlying hardware is abstracted through C, yet that abstraction, over all these years of technical advances, hasn't really changed!

# So when I say that in C a pointer is a memory address, you might ask, “is that a separate type from integer with a bunch of separate operations you can do on it?” and I might answer “it’s C, so I just mean there are a bunch of pointer operations that you can do with any piece of data anywhere inside your process.” The theme here is “C doesn’t track your stuff for you at runtime, who do you think C is, your mother?” The other, related theme is “C assumes when you tell it something you know what you’re doing, whether you actually do or not.” And if not, eh, crashes happen.

# A side effect of all of this “made of bits” and “track it yourself” stuff is that often you’ll do type tagging. You keep one piece of data that says what type another piece of data is, and then you interpret the second one completely differently depending on the first one. Wait, what? Okay, so, an example: if you know you could have an integer or a string, you keep a tag, which is either 0 for integer or 1 for string. When you read the object, first you check the tag for how to interpret the second chunk of bits. When you set a new value (which could be either integer or string) you also set the tag to the correct value. Does this all sound disorganized and error-prone? Good, you’re understanding a bit of what C is like.
#  - tagged unions

# in modern processors, values returned by a memory allocator are a multiple of 8, and so, the last three bits are unused (incoming hack!)

# If the final bit is a “1” then the reference contains a Fixnum. If the final two bits are “10” then it’s a Float. And if the last four bits are “1100” then it’s a Symbol. But the last three of “1100” are still illegal for an allocated pointer, so it works out.
#  - true, false, undef, nil (1000) have special values too
#  - must be a simple switch reading the bits from right to left, with the most used/optimized kept to the right-most side

# in C
# // Check if a reference is an immediate Fixnum
# define RB_FIXNUM_P(f) (((int)(SIGNED_VALUE)(f))&RUBY_FIXNUM_FLAG)

# // Convert a C int into a Ruby immediate Fixnum reference
# define RB_INT2FIX(i) (((VALUE)(i))<<1 | RUBY_FIXNUM_FLAG)

# // Convert a Ruby immediate Fixnum into a C int - RSHIFT is just >>
# define RB_FIX2LONG(x) ((long)RSHIFT((SIGNED_VALUE)(x),1))


# symbols use string interning: keep a table that maps symbol names to fixed-length keys
# string intern/symbol/atom
# in GC langs, it usually does this for the String impl, whereas lispy langs use a distinct symbol class


# rb(main):080> require 'objspace'
# => false
# irb(main):081> ObjectSpace.memsize_of(2**62-1)  # immediate value
# => 0
# irb(main):082> ObjectSpace.memsize_of(2**62)    # RVALUE IMMEDIATE
# => 40
# irb(main):083> ObjectSpace.memsize_of(2**100)   # RVALUE IMMEDIATE
# => 40
# irb(main):084> ObjectSpace.memsize_of(2**1000)  # RVALUE POINTER
# => 168

# END stack overflow answer




# check sizes of various data types


# require 'objspace'
# => # NOTE: 20 for the struct class and 20 for two ints..?
# (main):014> ObjectSpace.memsize_of(1)
# => 0
# irb(main):016> ObjectSpace.memsize_of(1.0)
# => 0
# irb(main):019> a = [1, 2, 3, 4]
# => [1, 2, 3, 4]
# irb(main):020> ObjectSpace.memsize_of(a)
# => 40
# NOTE: ints are too small to measure


#irb
# rb(main):054> true.size
# (irb):54:in `<main>': undefined method `size' for true:TrueClass (NoMethodError)
# rb(main):052> true.class
# => TrueClass

# rb(main):055> :s.size
# => 1
# 1 words * 8 = 1 byte
# uses a global symbol table (hash?) mapping symbols to integers
# immutable

# rb(main):049> 1.size
# => 8
# # 8 words * 8 = 64 bytes!! yikes

# rb(main):053> 1.0.size
# (irb):53:in `<main>': undefined method `size' for 1.0:Float (NoMethodError)

# rb(main):022> "a".size
# => 1
# 1 words * 8 = 1 byte


# data containers

# rb(main):106> Data = Struct.new(:int, :int2)
# => Data
# irb(main):107> d = Data.new(1, 2)
# => #<struct Data int=1, int2=2>
#irb(main):108> d.size
#=> 2 # * 8 = 16
#irb(main):109> ObjectSpace.memsize_of(d)
#=> 40

rb(main):029> a
=> [1, 2, 3, 4]
rb(main):024> a.size
=> 4

rb(main):027> h = {a:0, b:1}
=> {:a=>0, :b=>1}
irb(main):028> h.size
=> 2
irb(main):029> 

rb(main):031> r = 1..10
=> 1..10
irb(main):032> r.size
=> 10




# For custom objects, you might define a size method:

class MyObject
 def initialize(data)
     @data = data
       end

 def size
     @data.size # Or any logic to determine the 'size'
       end
       end

my_object = MyObject.new([1, 2, 3])
puts "MyObject size: #{my_object.size}"
# 3
# custom function doesn't include the size of the object..

# rb(main):073> ObjectSpace.memsize_of(my_object)
# => 40
# 3*8 for the data, 1*8 for the class instance


# For memory usage in general, use ObjectSpace:
object = "a very long string"
puts "Object memory size(approximate): #{ObjectSpace.memsize_of(object)}"
